{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5efbb14c",
   "metadata": {},
   "source": [
    "### Clelia Caetano 2023060 (CA2_SEM2)\n",
    "### MSc. in Data Analytics\n",
    "### Project Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb91c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'local[*]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sc master - running locally\n",
    "sc.master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8b8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334b3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import os\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073afae",
   "metadata": {},
   "source": [
    "### Initialize Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8bdecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session with necessary configurations\n",
    "spark = SparkSession.builder.appName('ProjectTweets') \\\n",
    "                    .config(\"spark.some_config_option\", \"config_value\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d37eab8",
   "metadata": {},
   "source": [
    "### Read the Data from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739e385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|number|  id_tweet|                date|   query|        user_id|               tweet|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     1|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|is upset that he ...|\n",
      "|     2|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus|@Kenichan I dived...|\n",
      "|     3|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|my whole body fee...|\n",
      "|     4|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli|@nationwideclass ...|\n",
      "|     5|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|@Kwesidei not the...|\n",
      "|     6|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|         Need a hug |\n",
      "|     7|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ|@LOLTrish hey  lo...|\n",
      "|     8|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|@Tatiana_K nope t...|\n",
      "|     9|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo|@twittera que me ...|\n",
      "|    10|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break in p...|\n",
      "|    11|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|I just re-pierced...|\n",
      "|    12|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC|@caregiving I cou...|\n",
      "|    13|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert|@octolinz16 It it...|\n",
      "|    14|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves|@smarrison i woul...|\n",
      "|    15|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess|@iamjazzyfizzle I...|\n",
      "|    16|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|Hollis' death sce...|\n",
      "|    17|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|about to file taxes |\n",
      "|    18|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed|@LettyA ahh ive a...|\n",
      "|    19|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee|@FakerPattyPattz ...|\n",
      "|    20|1467813985|Mon Apr 06 22:20:...|NO_QUERY|         quanvu|@alydesigns i was...|\n",
      "+------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the data.csv file\n",
    "    data = spark.read.csv(\"file:///home/hduser/Desktop/CA2_SEM2/ProjectTweets.csv\", header=True, inferSchema=True)\n",
    "\n",
    "    # Check if the data was loaded successfully\n",
    "    if data is not None:\n",
    "        # Define your column names\n",
    "        new_column_names = [\"number\", \"id_tweet\", \"date\", \"query\", \"user_id\", \"tweet\"]\n",
    "\n",
    "        # Use the alias method to rename the columns\n",
    "        for i in range(len(new_column_names)):\n",
    "            data = data.withColumnRenamed(data.columns[i], new_column_names[i])\n",
    "\n",
    "        # Create a temporary table from the DataFrame\n",
    "        data.createOrReplaceTempView(\"CA2_ProjectTweets\")\n",
    "\n",
    "        # Run Spark SQL queries using the same SparkSession\n",
    "        data = spark.sql(\"SELECT * FROM CA2_ProjectTweets\") \n",
    "\n",
    "        # Display the first 20 rows\n",
    "        data.show()\n",
    "    else:\n",
    "        print(\"Data not loaded successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d33efac",
   "metadata": {},
   "source": [
    "### Create a Hive database in Spark application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edfe5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-20 00:47:40,701 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-10-20 00:47:40,702 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "2023-10-20 00:47:45,521 WARN metastore.ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "2023-10-20 00:47:45,522 WARN metastore.ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore hduser@127.0.1.1\n",
      "2023-10-20 00:47:46,555 WARN metastore.ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "2023-10-20 00:47:59,830 WARN session.SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "2023-10-20 00:48:00,132 WARN conf.HiveConf: HiveConf of name hive.internal.ss.authz.settings.applied.marker does not exist\n",
      "2023-10-20 00:48:00,133 WARN conf.HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "2023-10-20 00:48:00,134 WARN conf.HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n"
     ]
    }
   ],
   "source": [
    "# Save the DataFrame as a Hive table\n",
    "data.write.mode(\"overwrite\").saveAsTable(\"ca2_projecttweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697d6d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the current database\n",
    "spark.sql(\"USE ca2_projecttweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60af3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a SQL query to select all rows from the table\n",
    "result = spark.sql(\"SELECT `number`, `id_tweet`, `date`, `query`, `user_id`, `tweet` FROM ca2_projecttweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3ea44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save the preprocessed data as a new table if needed\n",
    "result.write.mode(\"overwrite\").saveAsTable(\"preprocessed_ca2_projecttweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "811dcc55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: integer (nullable = true)\n",
      " |-- id_tweet: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- query: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- tweet: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access the Hive table and create a DataFrame\n",
    "data = spark.table(\"preprocessed_ca2_projecttweets\")\n",
    "\n",
    "# Print the schema\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0e5502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f010802c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b5befb8",
   "metadata": {},
   "source": [
    "### Create a HBase database in Spark application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39eb177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29414eef",
   "metadata": {},
   "source": [
    "#### Store the data from Spark DataFrame into HBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9b3a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install happybase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d616b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import happybase\n",
    "\n",
    "# Specify your HBase host and port\n",
    "hbase_host = \"localhost\"  # Replace with your HBase host\n",
    "hbase_port = 9095  # Replace with your HBase port\n",
    "\n",
    "# Initialize the HappyBase connection\n",
    "connection = happybase.Connection(host=hbase_host, port=hbase_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451ca56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
